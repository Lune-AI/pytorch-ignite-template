# Reproducibility
seed: 42 # rng seed for torch, random and numpy
checkpoint: False # TODO: implement checkpoint resumation

# specify the default training parameters
defaults:
  - _self_
  - data: cifar10.yaml # dataset configuration
  - model: cifar10.yaml # architecture parameters

optimizer:
  _target_: torch.optim.Adam

criterion:
  _target_: torch.nn.CrossEntropyLoss

engine:
  _target_: src.engines.cifar10_engine.create_engine

callbacks:
  add_lr_scheduler:
    _target_: src.callbacks.started.add_lr_scheduler

  print_learning_rate:
    _target_: src.callbacks.epoch_completed.print_learning_rate

  evaluate_model:
    _target_: src.callbacks.epoch_completed.evaluate_model

# Commonly changed hyperparameters
params:
  batch_size: 128
  epochs: 20

# Hardware specific parameters
compute:
  backend: # Can be either nccl, gloo, xla-tpu or left empty for None
  nproc_per_node: # Integer, left empty for None
